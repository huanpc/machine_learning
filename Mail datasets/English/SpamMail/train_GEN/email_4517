<message>
<date> sat, 1 mar 2003 10:35:54 +0000 (gmt) </date>
<from> ac.uk </from>
<to> ac.uk </to>
<subject>
<text_normal> 

^ re : txt classif 
</text_normal>
</subject>
<content-type> text/plain; charset=us-ascii </content-type>
<message_body>
<text_normal> 

^ thanks a lot &name - speak to you about it sometime fairly early next week . 
^ have a good weekend ! 
^ &char 
^ on &name , &num &name &num , &name &name wrote : 
</text_normal>
<text_embedded> 

^ &name -- 
^ the papers are now linked off of &website having any difficulty finding them . 
^ cheers , 
^ &name 
^ on &name , &num &name &num , &name &name wrote : 
<text_embedded> 

^ the latest version of the relvance vector machine is described in &name &name of sparse classifiers , &name and jain -- shld be able to find this on the web ( but ping me if you ca n't) 
^ &name &char neural networks for &name &name . 
^ &name , &num ch1-4 is good , but for &name the tipping paper introducing &name reference in first paper is good . 
^ you need to understand &num ) diff btwn linear / non-linear classif and relationship to independence assumptions &num ) kernel methods for bldg non-linear classif 
^ logistic regression / classification ( aka maxent ) for txt classif is also potentially relevant -- see paper by &name and &name &num in &name also available via web but i do n't remember the 
^ the datasets are mostly in /usr / groups / corpora 
</text_embedded>

</text_embedded>
</message_body>
</message>
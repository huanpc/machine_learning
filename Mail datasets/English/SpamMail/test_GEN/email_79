<message><date> thu, 17 apr 2003 17:06:34 +0200 </date><from></from><to> edu edu </to><subject><text_normal> ^ re : multilingual text categorisation </text_normal></subject><content-type> text/plain; charset="iso-8859-1" </content-type><message_body><text_normal> ^ i use the clef corpora that i have managed for the problem of multilingual text categorisation . ^ i do not know if my choise of this corpus will affect the result . ^ note that it is very difficult to obtain corpora for this task . ^  ame </text_normal><text_embedded> ^ original message from  ame  ame (  mail )  ame , ^ what corpus are you using for your experiments ? ^ i think that the second solution will work well if you are using a general corpus . ^ however , one of the problem i have observed when using  ame in other domains ( like medicine or biology ) is that the translation of domain specific terms will be very poor . ^ in this case you will need have a domain specific multilingual dictionary that could be included in the  ame system . ^  ame  ame ^ on thursday  um april  um  um :  um am ,  ame  ame wrote : <text_embedded> ^ dear  ame , ^ for some days i have sent a message to ask whether you know references in ' categorization of multilingual texts ' . ^ i thank all the people who answered my question . ^ i asked this question because i have been interested on this subject for some months . ^ according to the answers received , i can say that there are not works on this subject compared to works in the  ame ( cross-language information retrieval ) . ^ the problem , that i treat , is as follows : ^ suppose that we have some corpora in several languages . ^ the subjects of these corpora are comparable . ^ each text of these corpora is label by  um or more classes ( subjects ) . ^ it is about sotries of newspapers in several languages which cover different subjects like ' conflict in  ame , conflict of interests in  ame ,  ame  ame  ame , destruction of ukrainian nuclear weapons ,  ame american car industry , . ... the objective is to use the techniques of texts categorization on these corpora . ^ our hope is to be able to know the subject of each new text whatever its language . ^ at the beginning i had  um possible solutions , suppose that  ame  um , .. ,  har where  har is the number of languages and  ame  um , ... ,  ame , where c_l_i is the number of classes for the language  ame : ^  um the first solution is to learn a model for each language ; thus if i have  um languages , i must learn  um models (  um for each ) , then , in the phase of classification , for each new text one identifies its language and applies the model of this language on it . ^ this is the simplest solution and the most direct but this solution is limited because it supposes to have sufficient quantity of texts for each class and for each language and it require  har learning . ^  um the second solution is to learn on only  um language  ame ( as we do usually ) and then , for each new text , one identifies its language and one translates it by an automatic translator into the language  ame and then one applies the learned model of the language  ame on the translated text . ^ i made experiments on the  um approaches and according to obtained results the second solution perfomes well . ^ therefore , the introduction of machine translation , in the process of categorization , helps to recognize the subject of a text . ^ all comments , helps or ideas are welcome . ^  ame , </text_embedded>^ dr.  ame  ame  ame school of informatics department of library and information studies  um  ame  ame  ame , ny  um  ame : (  um )  um ext . ^  um  ame : (  um )  um </text_embedded><text_normal> ^  ame  ame  ame laboratory  ame  um university  ame -  ame </text_normal></message_body></message>
<message><to> edu </to><subject><text_normal> ^ re : [  ame ]  ame / recall  um point for  ame  ame classifier </text_normal></subject><from> edu </from><content-type> text/plain; charset=us-ascii </content-type><date> mon, 09 jun 2003 17:02:36 -0400 </date><message_body><text_normal> ^  mail said : </text_normal><text_embedded> ^ thanks for your reply . ^ my main concern with this type of thresholding is that this is no longer a  ame classifier , because the  ame decision rule assigns each example to the class with the highest score ( posterior probability ) , regardless of the absolute values of the scores . </text_embedded><text_normal> ^ in fact , it is still a naive  ame classifier , though with an altered class prior . ^ for example , if the class  um likelihood is twice the class  um likelihood , then an even prior (  um for both classes ) will yield  har '  um ' label ( since the posterior for the class  um will be larger ) . ^ but , a prior that weights class  um sufficiently heavily ( e.g.  um for class  um ,  um for class  um ) will yield  har '  um ' label for the document . ^ if you look at log-probabilities ,  ame  ame is simply a linear classifier and the class prior is the ' bias ' or ' threshold ' term . ^ section  um of this paper might help to clarify things a bit : ^  ebsite ^  ame </text_normal></message_body></message>